{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPINF 2100: Homework 09\n",
    "\n",
    "## Vedant Kansara\n",
    "\n",
    "### Assigned: Monday November 15, 2021\n",
    "\n",
    "### DUE: Tuesday November 23, 2020 at 11:00PM EST\n",
    "\n",
    "You may add as many code and markdown cells as you see fit to answer the questions.  \n",
    "\n",
    "**NOTE**: The assignment is due within the Thanksgiving break in case you are traveling over the weekend. You may turn the assignment in by Monday without any penalty. It is a short assignment, and so you should try to complete it by the typical Sunday due date.\n",
    "\n",
    "#### Write the name of your collaborators here\n",
    "\n",
    "None.\n",
    "\n",
    "### Overview\n",
    "\n",
    "You will consider different types of regularization methods in this assignment. You will fit logistic regression models considering the Ridge and Lasso penalties to understand the influence of the regularization strength on the coefficient estimates. You will also tune the regularization strength with cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules\n",
    "You will use the following modules in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use `statsmodels` and `sklearn` to fit the models. The `statsmodels` formula api, the `dmatrices()` function from `patsy` and the `sklearn` logistic regression method is imported in for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "from patsy import dmatrices\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will tune the regularization in logistic regression using cross-validation. The `sklearn` built-in tuning function is loaded in for you below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data\n",
    "The training data is read in for you in the cell below. As shown by the `.info()` output, there are 4 continuous inputs `x1` through `x4` and a response `y`. The response is a binary outcome that has already been encoded as 0 and 1 for you, that is why it is an integer data type. A value of 0 represents the non-event, while a value of 1 represents the event. The unique values of `y` are displayed for you to confirm it is a binary variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200 entries, 0 to 199\n",
      "Data columns (total 5 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   x1      200 non-null    float64\n",
      " 1   x2      200 non-null    float64\n",
      " 2   x3      200 non-null    float64\n",
      " 3   x4      200 non-null    float64\n",
      " 4   y       200 non-null    int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 7.9 KB\n"
     ]
    }
   ],
   "source": [
    "train_url = 'https://raw.githubusercontent.com/jyurko/CMPINF_2100_Fall_2021/main/HW/09/hw09_classify_train.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_url)\n",
    "\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 01\n",
    "\n",
    "You will start out by fitting a logistic regression model with `statsmodels`.\n",
    "\n",
    "### 1a)\n",
    "\n",
    "Fit a logistic regression model with all pair wise interactions between the inputs. Assign the result to the `stats_fit` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1a) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.498603\n",
      "         Iterations 8\n"
     ]
    }
   ],
   "source": [
    "formula_fit = 'y ~ (x1*x2*x3*x4)'\n",
    "\n",
    "stats_fit =  smf.logit(formula = formula_fit, data=train_df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b)\n",
    "Display the summary of the for your logistic regression model. How many coefficients were estimated? Which coefficients are statistically significant?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1b) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  200\n",
      "Model:                          Logit   Df Residuals:                      184\n",
      "Method:                           MLE   Df Model:                           15\n",
      "Date:                Tue, 23 Nov 2021   Pseudo R-squ.:                  0.2764\n",
      "Time:                        14:58:23   Log-Likelihood:                -99.721\n",
      "converged:                       True   LL-Null:                       -137.82\n",
      "Covariance Type:            nonrobust   LLR p-value:                 3.441e-10\n",
      "===============================================================================\n",
      "                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "Intercept      -0.0589      0.184     -0.320      0.749      -0.419       0.301\n",
      "x1              0.1457      0.219      0.665      0.506      -0.283       0.575\n",
      "x2              0.5600      0.255      2.200      0.028       0.061       1.059\n",
      "x1:x2           2.2415      0.434      5.169      0.000       1.392       3.091\n",
      "x3             -0.1006      0.174     -0.579      0.563      -0.441       0.240\n",
      "x1:x3          -0.2036      0.210     -0.971      0.331      -0.614       0.207\n",
      "x2:x3          -0.1655      0.233     -0.711      0.477      -0.622       0.291\n",
      "x1:x2:x3       -0.7273      0.424     -1.713      0.087      -1.559       0.105\n",
      "x4             -0.1998      0.190     -1.052      0.293      -0.572       0.172\n",
      "x1:x4           0.0213      0.214      0.099      0.921      -0.399       0.442\n",
      "x2:x4          -0.6020      0.247     -2.440      0.015      -1.086      -0.118\n",
      "x1:x2:x4       -0.4364      0.412     -1.059      0.290      -1.244       0.371\n",
      "x3:x4          -0.1257      0.195     -0.645      0.519      -0.508       0.256\n",
      "x1:x3:x4       -0.0655      0.278     -0.236      0.814      -0.610       0.479\n",
      "x2:x3:x4        0.1859      0.223      0.832      0.405      -0.252       0.624\n",
      "x1:x2:x3:x4     0.1167      0.474      0.246      0.805      -0.812       1.046\n",
      "===============================================================================\n"
     ]
    }
   ],
   "source": [
    "print(stats_fit.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_fit.params.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary table we can observe that only the coefficient `x2` coefficient with interaction between `x1:x2`,`x2:x4` are significantly significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1c)\n",
    "In addition to displaying the summary report, we have visualized the coefficient estimates and confidence intervals. Visualize the coefficient estimates and confidence for your logistic regression model.  \n",
    "\n",
    "The previous assignment provided a function to you plot the coefficients. You are allowed to reuse the function from the previous assignment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1c) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_coefplot(model_object, figsize_use=(10, 5)):\n",
    "    fig, ax = plt.subplots(figsize=figsize_use)\n",
    "    \n",
    "    ax.errorbar(y = model_object.params.index,\n",
    "               x = model_object.params,\n",
    "               fmt = 'o', color = 'black', ecolor='black',\n",
    "               xerr = 2 * model_object.bse,\n",
    "               elinewidth = 3, ms=10)\n",
    "    \n",
    "    ax.axvline(x = 0, linestyle='--', linewidth=5, color='grey')\n",
    "    \n",
    "    ax.set_xlabel('coefficient value')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAn4AAAE9CAYAAACV9G8/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAA2B0lEQVR4nO3df7RcdX3v/+cL3CGGkC/N19RKIcIa7bdXcQz1BKRehIuKHJc3rTq3tl8ElXYNZoLYcw+2diHJJNJVfnh6eu89WfEb5nLbkNAqp7XwVUehFKitoAkWRnJra+crtyC9iLBcHTpVJvD+/jE7eE7Oj5xzcs7sOTOvx1p7ObP357P3e2cAX/nsHx9FBGZmZmbW+47LugAzMzMz6wwHPzMzM7M+4eBnZmZm1icc/MzMzMz6hIOfmZmZWZ9w8DMzMzPrEy/LuoDl4BWveEWcfvrpWZdhlqlGozFl3UknnZRBJWZmNpuHHnroBxGxbrptDn5zcPrpp3PgwIGsyzDL1Pbt26es27ZtWwaVmJnZbCT9r5m2+VKvmZmZWZ9w8DMzMzPrEw5+ZmZmZn3Cwc/MzMysTzj4mZmZmfUJP9VrZnNy/vnnz6t9vV5nZGSEvXv38txzz7F69Wo+8IEPMDw8TC6XW6IqzcxsNoqIrGvoegMDA+HXuZjNXbVapVAo0Gq1aLVaL61PkoQkSRgfH2dwcDDDCs3MepekhyJiYLptC7rUK+nLkn4o6QsL6HuTpG9Lqkn6vKST59H31ZIekvSwpIOSPjLf46f7uVpSSHrFQvqb2czq9TqFQoFmszkp9AG0Wi2azSaFQoF6vZ5RhWZm/Wuh9/jdBFy6wL53A2dGRB74B+B35tH3n4FfjIgNwDnAJySdMp+DSzoNeAfwT/PpZ2ZzMzIyMiXwHanVajE6OtqhiszM7LBZg5+kjenI3EpJJ6ajbGdGxD3A1PmbJve9Q9Jl6ecrJO0DiIi7IuJQ2uxB4NR5HPf5iPhx2uyEmeqf6dipUeC3AF/j7jHlchlJXjJedu3aNafgt3Pnzsxr7felXC535l9OM+sasz7cERH7Jd0JXAe8HNgbEY/O1F7SDuBARNwJFIG/kfRdYBh48zRdLgc+m/Y9BahExLtmO67aI3ZfBF4DfDwinpzrsSVtAr4XEY9ImvUPRlIx3Q/r16+fta2ZmZnZcjCXp3p3APuBHwFXzdYwIrZO+PyUpK3AvcB7IuLZiW0lXQMcAg6PBD4JvOtox42Ix4F8GhT/XNJ4RDx1tGNLWgVcA1w0h3MmInYDu6H9cMdc+piZmZl1s7nc47cWWA2cBKyc5/7fADwDTLoPT9IHgXcDl8TMjxXPetw0KB4EzpvjsXPAGcAjkh6jfYn5m5J+Zh7nY12sXC4TEV4yXjZv3kySJLP+VkmSsGXLlsxr7ffFl3rN+s9cRvx2A9fSDk03AFfOZceSzgYGgbOA+yXdFRHflXQx8NvA+RHRnM9xJZ0KPBMR/ybpp4C3AL8/x2N/C/jpCW0eAwYi4gdzOR+zfnffffdNWXfBBRdMWTc8PMwf/dEfzXqfX5IkDA0NLWJ1ZmY2F7MGP7UfkDgUEbdJOh74mqQLge3AzwOrJT0B/HpEfOXwfXbAV4CbgQ9HxJOShoFb0r5jtB/MuDu9z+7BiPjIxHv8Zjnu8cCIpAAEfDoNdMzl2BHhS7ZmC3T//fdPWTdd8MvlcoyPjx/1PX5+ibOZWef5Bc5z4Bc4m8H27dunrNu2bduM7ev1OqOjo9x6660vzdxx6aWXMjQ05NBnZraENMsLnD1lm5ktiVwux9jYGGNjY1mXYmZmqYW+wNnMzMzMlhkHPzMzM7M+4eBnZmZm1icc/MzMzMz6hIOfmZmZWZ9w8DOzjqvX65RKJdasWcNxxx3HmjVrKJVK1Ov1rEszM+tpHQ9+kjZIekDSQUk1Se+fZ/9Ppf0elnRX+uLn+dawRtL3JPk9E2YdVq1WyefzVCoVGo0GEUGj0aBSqZDP56lWq1mXaGbWs7IY8WsCl0XE64GLgT+QdPI8+t8UEfmI2AB8Adi6gBo+BUydhsDMllS9XqdQKNBsNqdM6dZqtWg2mxQKBY/8mZktkSUNfpI2pqNzKyWdKOkgsCIivgMQEU8C3wfWTdP3jnTqNiRdIWlf2udfJjQ7EZgy9ch0x5V0ZrrtTcArgbsW+XTN7ChGRkZmncMX2gFwdHS0QxWZmfWXJQ1+EbEfuBO4DrgR2BsRjx7eLulsYAVQT7/vkLQp3VwEtko6DxgGPjqh3+9Kehy4hHTET9Ipkr4023ElHQeMAB9furM266xyuYykJV+mM9997Nq1a07Bb+fOnR05p8VYyuXyEvyqZmZLoxOXencA7wAGaIcwACS9CrgV+HBEvAgQEVsj4s7081O0Q929wHBEPHu4b0RcExGnAfuAK9N1T0bEu45y3BLwpYh4/GhFSypKOiDpwNNPP72wMzczMzPrIp0IfmuB1cBJwEpoP1wBfBH4ZEQ8OEvfNwDPADM9wHEb8L65Hhc4F7hS0mPAp4HLJF0/XeeI2B0RAxExsG7dlCvRZmZmZstOJ4LfbuBa2qNzN0haAXwe2BMRt8/UKb0MPAicBVwt6Yx0/WsnNNsEfHsuxwWIiEsiYn1EnA5cndbwiWM4N7PMlctlImLJl+nMdx+bN28mSZJZzydJErZs2dKRc1qMxZd6zWw5WeqHOy4DDkXEbcD1wEbgV4G3Ah9KX8nysKQNafsdkjZJOgG4Gbg8fQBkGLhF7RuNrpf0qKQacBHwsbTvS/f4TXdcSRcu5bma2dENDw/PKfgNDQ11qCIzs/6imf4mbz8xMDAQBw4cyLoMs0xt3759yrpt27bNez/VapVCoUCr1Zr0oEeSJCRJwvj4OIODg8dUq5lZP5P0UEQMTLvNwe/oHPzMFle9Xmd0dJRbb72V5557jtWrV3PppZcyNDRELpfLujwzs2XNwe8YOfiZmZnZcjFb8PNcvWZmZmZ9wsHPzMzMrE84+JmZmZn1CQc/MzMzsz7h4GdmQPtJ21KpxJo1azjuuONYs2YNpVKJer2edWlmZrZIMgl+kr4s6YeSvrCAvp+SVEtf/HyXpJmmc5ttH2skfU/S2Hz7mvWiarVKPp+nUqnQaDSICBqNBpVKhXw+T7VazbpEMzNbBJm8zkXS24BVwBUR8e559l0TEf+Sfr4KeF1EfGSe+/gvwDrg2Yi48mjt/ToX62X1ep18Pk+z2ZyxzapVq/iN3/gN1q5dO2n9Ql7gbGZmSyuz17lI2piOzq2UdKKkg5LOjIh7gMZR+t6RTr2GpCsk7QM4HPpSJwJTkutMx023vQl4JXDXIp2m2bI2MjIyaQaN6bRaLR544IEOVWRmZktlSYNfROwH7gSuA24E9kbEozO1PzxXb/q1CGyVdB7tuXo/OqHd70p6HLgE2Jque2mu3pmOK+k4YAT4+OKeqfW6crmMpJ5cdu3aNafgV6vVpqzPuvbFWsrl8hL9k2Nm1l06cY/fDuAdwADtEDajiNgaEXemn5+iHeruBYYj4tkJ7a6JiNOAfcCV6bonI+JdRzluCfhSRDx+tKIlFSUdkHTg6aefntuZmvWw559/PusSzMzsGHUi+K0FVgMnASvn2fcNwDPATA9w3Aa8bx7HPRe4UtJjwKeByyRdP13niNgdEQMRMbBu3bp5lm3We1asWJF1CWZmdow6Efx2A9fSHp27Ya6dJJ0NDAJnAVdLOiNd/9oJzTYB357rcSPikohYHxGnA1cDeyLiE/M6G+tL5XKZiOjJZfPmzSRJMuv5J0lCPp+fsj7r2hdr8aVeM+sXS/1wx2XAoYi4Dbge2CjpQklfBW4H3ibpCUnvTNvvkLRJ0gnAzcDlEfEk7Xv8bpEk4HpJj0qqARcBH0v7vnSP30zHXcpzNVuuhoeH5xT8zj333A5VZGZmSyWT17ksN36di/W6arVKoVCg1WpNetAjSRKSJGF8fJxvfOMbU/r5dS5mZt1HWb3OxcyWh8HBQWq1GsVicdLMHcVikVqtxuDgYNYlmpnZInhZ1gWYWXfI5XKMjY0xNuYJbczMepVH/MzMzMz6hIOfmZmZWZ9w8DMzMzPrEw5+ZmZmZn3Cwc/MzMysTzj4mfWRer1OqVSa9MqWUqlEvV7PujQzM+uAZRX8JL1a0kOSHpZ0UNJHFrifqyWFpFcsdo1m3aparZLP56lUKjQaDSKCRqNBpVIhn89TrVazLtHMzJbYsgp+wD8DvxgRG4BzgE9IOmU+O5B0GvAO4J8Wvzyz7lSv1ykUCjSbzUkzcwC0Wi2azSaFQsEjf2ZmPa5rX+AsaSPw34GzgeOBbwDvj4hH0yYnMENwlXQH8KcRsUfSFcBbI+KSdPMo8FvAHUtZv1k3GRkZmRL4jtRqtRgdHZ3xBc7nn3/+UpRmZmYd1NVz9Uq6DlgJvBx4IiJ+Lx2x+yLwGuDjEbEzbbsDOBARd0p6JfA3wIdph8c3R8SzkjYBb4uIj0l6DBiIiB8crQ7P1WvzUS6X2b59e9Zl9JRt27ZRLpezLsPMbFmYba7erh3xS+0A9gM/Aq4CiIjHgXx6iffPJY1HxFMRsfVwp4h4StJW4F7gPWnoWwVcA1w0lwNLKgJFgPXr1y/mOZmZmZllotvv8VsLrAZOoj3y95KIeBI4CJw3Q983AM8Ah+8BzAFnAI+ko32nAt+U9DPTdY6I3RExEBED69atO9bzMDMzM8tct1/qvRP4E9qB7VXA9cAzEfFvkn4K+Drwvoj41hH9zgZ2A+8C7gcuiojvHtHmMXyp1/pEqVSiUqnMep9fkiQUi8UZ7/EzM7PlYbZLvV074ifpMuBQRNxGO/BtBF4PfF3SI7QD3acPhz5JOyRtknQCcDNweToqOAzcIkmZnIhZFxgeHiZJklnbJEnC0NBQhyoyM7MsdPWIX7fwiJ/1gmq1SqFQoNVqTRr5S5KEJEkYHx9ncHAwwwrNzGwxLMsRPzNbXIODg9RqNYrF4qSZO4rFIrVazaHPzKwPeMRvDjziZwb33XfflHUXXHBBx+swM7PZLefXuZhZl7j//vunrHPwMzNbXnyp18zMzKxPOPiZmZmZ9QkHPzMzM7M+4eBn1iH1ep1SqTTpidpSqUS9Xs+6NDMz6xOZBD9JX5b0Q0lfWEDfmyR9W1JN0uclnbyAfayR9D1JnqLAOqJarZLP56lUKjQaDSKCRqNBpVIhn89TrVazLtHMzPpAViN+NwGXLrDv3cCZEZEH/gH4nQXs41O0Z/4wW3L1ep1CoUCz2ZwyZVqr1aLZbFIoFDzyZ2ZmS25Jg5+kjenI3EpJJ0o6KOnMiLgHaByl7x3ptG1IukLSPoCIuCsiDqXNHgROnetx021vAl4J3LWIp2o2o5GRkVnnyIV2ABwdHe1QRWZm1q+WNPhFxH7gTuA64EZgb0Q8OlP7w/Ptpl+LwFZJ59Geb/ej03S5HKimfU+R9KXZjivpOGAE+PhinF8vKpfLSPKyiMuuXbvmFPx27tyZea2zLdPJuqbZlnK5vAT/hpiZLW+deIHzDmA/8CPgqtkaRsTWCZ+fkrQVuBd4T0Q8O7GtpGuAQ8DhkcAngXcd5bgl4EsR8fhM/0c2Yf9F2uGT9evXz36GZmZmZstAJ4LfWmA1kAArgX+dR983AM8Ap0xcKemDwLuBt8XMc85Nd9xzgfMkldJtKyQ9FxGfOLJzROwGdkN7yrZ51GxmZmbWlTrxcMdu4FraI3M3zLWTpLOBQeAs4GpJZ6TrLwZ+G9gUEc35HDciLomI9RFxOnA1sGe60NfPyuUyEeFlEZfNmzeTJMmsf+5JkrBly5bMa51tmU7WNc22+FKvmdlUS/1wx2XAoYi4Dbge2CjpQklfBW4H3ibpCUnvTNvvkLRJ0gnAzcDl0b6EOwzcovb12THgJOBuSQ9L+kza96V7/GY67lKeq9lMhoeH5xT8hoaGOlSRmZn1K830N3n7iYGBgThw4EDWZdgyVq1WKRQKtFqtSQ96JElCkiSMj48zODiYYYVHt3379inrtm3blkElZmY2G0kPRcTAdNs8c4dZBwwODlKr1SgWi5Nm7igWi9Rqta4PfWZm1hs68XCHmQG5XI6xsTHGxjxhjJmZZcMjfmZmZmZ9wsHPzMzMrE/4Uq+ZzYkf5DAzW/484mdmZmbWJxz8zMzMzPqEg5/ZUdTrdUql0qTXsJRKJer1etalmZmZzcuyCn6SNkh6QNJBSTVJ71/gfq6WFJJesdg1Wm+pVqvk83kqlQqNRoOIoNFoUKlUyOfzVKvVrEs0MzObs2UV/IAmcFlEvB64GPgDSSfPZweSTgPeAfzT4pdnvaRer1MoFGg2m5Nm2wBotVo0m00KhYJH/szMbNno2uAnaWM6qrdS0omSDgIrIuI7AOkcvt8H1k3T9450vl4kXSFp34TNo8BvAZ6rzmY1MjIyJfAdqdVqMTo62qGKzMzMjk3XBr+I2A/cCVwH3AjsjYhHD2+XdDawAqin33dI2pRuLgJbJZ0HDAMfTdtsAr4XEY907ET6VLlcRtKyXnbt2jWn4Ldz587Maz2WpVwud+YfCjMzy1y3v8dvB7Af+BFw1eGVkl4F3Ap8MCJeBIiIrYe3R8RTkrYC9wLviYhnJa0CrgEumsuBJRVpB0jWr1+/OGdjtoxt3759yjq/28/MbHnp2hG/1FpgNXASsBJA0hrgi8AnI+LBWfq+AXgGOCX9ngPOAB6R9BhwKvBNST8zXeeI2B0RAxExsG7dlKvJZmZmZstOtwe/3cC1wD7gBkkrgM8DeyLi9pk6pZeBB4GzgKslnRER34qIn46I0yPidOAJ4Bci4n8v+Vn0oXK5TEQs62Xz5s0kSTLreSZJwpYtWzKv9VgWX+o1M+sfXRv80oczDkXEbcD1wEbgV4G3Ah+S9HC6bEjb75C0SdIJwM3A5ekDIMPALZKUyYnYsjU8PDyn4Dc0NNShiszMzI5N197jFxF7gD3p5xeAc9JNe2Zov3XC1zdOWH8n7YdEjmx/+mLVar0pl8sxPj5OoVCg1WpNetAjSRKSJGF8fJxcLpdhlWZmZnPXtSN+Zt1gcHCQWq1GsVicNHNHsVikVqsxODiYdYlmZmZz1rUjfmbdIpfLMTY2xtjYWNalmJmZHROP+JmZmZn1CQc/MzMzsz7h4GdmZmbWJxz8zMzMzPqEH+4wszl79tln+drXvkatVuP5559nZGSED3zgAwwPD/u1NmZmy8CyG/GT9GVJP5T0hWPYx9WSQtIrFrM2s172ne98h127dvHNb36T559/HoBGo0GlUiGfz1OtVjOu0MzMjmbZBT/gJuDShXaWdBrwDuCfFq0isx5Xr9f53Oc+R6vV4sUXX5y0rdVq0Ww2KRQK1Ov1jCo0M7O56NrgJ2mjpJqklZJOlHRQ0pkRcQ/QOErfO9Ip35B0haR9EzaPAr8FxNJVb9ZbRkZGeOGFF2Zt02q1GB0d7VBFZma2EF0b/CJiP+2p1q4DbgT2RsSjM7U/PFdv+rUIbJV0Hu25ej+attkEfC8iHlnS4s3moVwuI6mrl127dk0Z6TtSq9Vi586dmdc6l6VcLnfmxzUz6zLd/nDHDmA/8CPgqtkaTpyrNyKekrQVuBd4T0Q8K2kVcA1w0VwOLKlIO0Cyfv36hVVvZmZm1kW6dsQvtRZYDZwErJxn3zcAzwCnpN9zwBnAI5IeA04FvinpZ6brHBG7I2IgIgbWrVu3kNrNzMzMukq3B7/dwLXAPuCGuXaSdDYwCJwFXC3pjIj4VkT8dEScHhGnA08AvxAR/3sJ6jabs3K5TER09bJ582aOP/74Wc8jSRK2bNmSea1zWXyp18z6VdcGv/ThjEMRcRtwPbBR0oWSvgrcDrxN0hOS3pm23yFpk6QTgJuByyPiSdr3+N0iSRmditmyNzw8zAknnDBrmyRJGBoa6lBFZma2EIrww61HMzAwEAcOHMi6DLNMVatVCoUCrVaLVqv10vokSUiShPHxcQYHBzOs0MzMACQ9FBED023r2hE/M+sug4OD1Go1isUia9as4bjjjmPNmjUUi0VqtZpDn5nZMuARvznwiJ+ZmZktFx7xMzMzMzMHPzMzM7N+4eBnZmZm1ie6feYOM+sS991335R1F1xwQcfrMDOzhXPwM7M5uf/++6esc/AzM1tefKnXrIfU63VKpdKk162USiXq9XrWpZmZWRfoy+AnaY2k70kay7oWs8VSrVbJ5/NUKhUajQYRQaPRoFKpkM/nqVarWZdoZmYZ68vgB3wKmHrdymyZqtfrFAoFms3mpFk1AFqtFs1mk0Kh4JE/M7M+17PBT9JGSTVJKyWdKOmgpDMlvQl4JXBX1jWaLZaRkZEpge9IrVaL0dHRDlVkZmbdqGeDX0TsB+4ErgNuBPYC/xMYAT6eYWnWA8rlMpK6Ztm1a9ecgt/OnTsXfIzpHGvd5XJ5CX4dMzObSa8/1bsD2A/8CLgKKAFfiojHZ/o/ssMkFYEiwPr165e4TDMzM7Ol1+vBby2wGkiAlcC5wHmSSun6FZKei4hPHNkxInYDu6E9V2/nSjYzMzNbGj17qTe1G7gW2AfcEBGXRMT6iDgduBrYM13oMzuacrlMRHTNsnnzZpIkmbXmJEnYsmXLgo8xnWOt25d6zcw6q2eDn6TLgEMRcRtwPbBR0oUZl2W2JIaHh+cU/IaGhjpUkZmZdaOeDX4RsSci3pt+fiEizomIv5yw/Q8j4srsKjRbPLlcjvHxcVatWjUlACZJwqpVqxgfHyeXy2VUoZmZdYOeDX5m/WZwcJBarUaxWJw0c0exWKRWqzE4OJh1iWZmlrFef7jDrK/kcjnGxsYYG/OkNGZmNpVH/MzMzMz6hIOfmZmZWZ9w8DMzMzPrEw5+ZmZmZn3Cwc/6Rr1ep1QqTXritVQqUa/Xsy7NzMysIzTTG/mX9KDSl4E3A38dEe+eZ9+bgP8IPA/UgQ9HxA/n2PfVwJ8Bx9Oexu2/RcRnjtZvYGAgDhw4MJ8yrctUq1UKhQKtVotWq/XS+iRJSJKE8fFxv+7EzMx6gqSHImJgum1ZjfjdBFy6wL53A2dGRB74B+B35tH3n4FfjIgNwDnAJySdssA6bJmo1+sUCgWazeak0AfQarVoNpsUCgWP/JmZWc9b0uAnaaOkmqSVkk6UdFDSmRFxD9A4St870mnXkHSFpH0AEXFXRBxKmz0InDqP4z4fET9Om52AL3X3hZGRkSmB70itVovR0dEOVWRmZpaNJQ0+EbEfuBO4DrgR2BsRj87UXtIOSZvSr0Vgq6TzgGHgo9N0uRyopn1PkfSlox1X0mmSasDjwA0R8eSxn+mxK5fLSPKyBMuuXbvmFPx27tyZea29upTL5c78i2RmZrPqxMwdO4D9wI+Aq2ZrGBFbJ3x+StJW4F7gPRHx7MS2kq4BDgGHRwKfBN51tONGxONAXu1LvH8uaTwinjqyFklF2uGT9evXz/lkzczMzLpVJy51rgVWAycBK+fZ9w3AM8Ck+/AkfRB4N3BJzPx0yqzHTYPiQeC86TpHxO6IGIiIgXXr1s2zbDMzM7Pus+RP9Uq6E/gT4AzgVRFxZbr+AuDqmZ7qlXQ2sJv2KN79wEUR8V1JFwO/D5wfEU/P57iSTgWeiYh/k/RTwNeB90XEt2Y7Bz/Vu7yVSiUqlcqsl3uTJKFYLHqOWzMzW/aU1VO9aj+ccSgibgOuBzZKulDSV4HbgbdJekLSO9P2OyRtknQCcDNweToyNwzcIknAGO1RvLslPSzpM2nfl+7xm+m4wL8Dvi7pEdph8tNHC322/A0PD5MkyaxtkiRhaGioQxWZmZllI5P3+C03HvFb/vwev2O3ffv2Keu2bduWQSVmZjabzEb8zLrF4OAgtVqNYrE4aeaOYrFIrVZz6DMzs77Qiad6zbpCLpdjbGzM9/GZmVnf8oifmZmZWZ9w8DMzMzPrEw5+ZmZmZn3Cwc/MzMysTzj4mZmZmfUJBz+zHlav1ymVSpNeYVMqlajX61mXZmZmGVhWwU/SBkkPSDooqSbp/fPs/6m038OS7pJ0ytF7mS1P1WqVfD5PpVKh0WgQETQaDSqVCvl8nmq1mnWJZmbWYcsq+AFN4LKIeD1wMfAHkk6eR/+bIiIfERuALwBbF79Es+zV63UKhQLNZnPKHMWtVotms0mhUPDIn5lZn+na4CdpYzo6t1LSiZIOAisi4jsA6Ry+3wfWTdP3jnS+XiRdIWlf2udfJjQ7EfB8ddaTRkZGpgS+I7VaLUZHRztUkZmZdYOuDX4RsR+4E7gOuBHYGxGPHt4u6WxgBVBPv++QtCndXAS2SjoPGAY+OqHf70p6HLgEj/jZHJTLZSQtq2XXrl1zCn47d+6c8z6nk8W5lcvlJfiVzcz6Q9cGv9QO4B3AAO3wB4CkVwG3Ah+OiBcBImJrRNyZfn6Kdqi7FxiOiGcP942IayLiNGAfcOVMB5ZUlHRA0oGnn3568c/MzMzMrMO6PfitBVYDJwErASStAb4IfDIiHpyl7xuAZ4CZHuC4DXjfTJ0jYndEDETEwLp1U64mm5mZmS073R78dgPX0h6du0HSCuDzwJ6IuH2mTull4EHgLOBqSWek6187odkm4NtLVbj1jnK5TEQsq2Xz5s0kSTLreSVJwpYtW+a8z+lkcW6+1GtmtnBdG/zShzMORcRtwPXARuBXgbcCH0pfyfKwpA1p+x2SNkk6AbgZuDx9AGQYuEXtm5Sul/SopBpwEfCxzp+Z2dIbHh6eU/AbGhrqUEVmZtYNXpZ1ATOJiD3AnvTzC8A56aY9M7Sf+KDGGyesv5P2QyIwy6Vds16Sy+UYHx+nUCjQarUmPeiRJAlJkjA+Pk4ul8uwSjMz67SuDX5mdmwGBwep1WqMjo5y66238txzz7F69WouvfRShoaG5h36zj///CWq1MzMOkUz3btjPzEwMBAHDhzIugwzMzOzo5L0UEQMTLeta+/xMzMzM7PF5eBnZmZm1icc/MzMzMz6hIOfmZmZWZ9w8DPrIfV6nVKpxJo1azjuuONYs2YNpVKJer2edWlmZtYFll3wk/RlST+U9IUF9P2UpFr64ue7JM00nZvZslOtVsnn81QqFRqNBhFBo9GgUqmQz+epVqtZl2hmZhlbdq9zkfQ2YBVwRUS8e55910TEv6SfrwJeFxEfOVo/v87Ful29Xiefz9NsNmdss2rVKmq12oJf2nzfffdNWXfBBRcsaF9mZrZ0luXrXCRtTEfnVko6UdJBSWdGxD1A4yh970infEPSFZL2ARwOfakTgeWVes1mMDIyMml2jum0Wi1GR0cXfIz7779/ymJmZstL1wa/iNhPe6q164Abgb0R8ehM7Q/P1Zt+LQJbJZ1He67ej05o97uSHgcuAbZO3ZPZVOVyGUldu+zatWtOwW/nzp0LPsZ0Fvs8yuXyEvx6ZmZ2WNcGv9QO4B3AAO3wN6OI2JrOy0tEPEU71N0LDEfEsxPaXRMRpwH7gCtn2p+koqQDkg48/fTTx34mZmZmZhnr9uC3FlgNnASsnGffNwDPADM9wHEb8L6ZOkfE7ogYiIiBdevWzfPQZmZmZt2n24PfbuBa2qNzN8y1k6SzgUHgLOBqSWek6187odkm4NuLV6r1snK5TER07bJ582aSJJn1HJIkYcuWLQs+xnQW+zx8qdfMbGl1bfBLH844FBG3AdcDGyVdKOmrwO3A2yQ9IemdafsdkjZJOgG4Gbg8Ip6kfY/fLWrfpHS9pEcl1YCLgI9lcW5mi214eHhOwW9oaKhDFZmZWTd6WdYFzCQi9gB70s8vAOekm/5yhvYTH9R444T1d9J+SARmubRrtpzlcjnGx8cpFAq0Wq1JD3okSUKSJIyPjy/4VS5mZtYbunbEz8zmZ3BwkFqtRrFYnDRzR7FYpFarMTg4mHWJZmaWsa4d8TOz+cvlcoyNjTE2NpZ1KWZm1oU84mdmZmbWJxz8zMzMzPqEg5+ZmZlZn3DwMzMzM+sTDn5mZmZmfcLBz6xP1et1SqXSpFe/lEol6vV61qWZmdkS6avgJ+nVkh6S9LCkg5I+knVNZlmoVqvk83kqlQqNRoOIoNFoUKlUyOfzVKvVrEs0M7Ml0FfBD/hn4BcjYgPtmUA+IemUbEsy66x6vU6hUKDZbE6a4QOg1WrRbDYpFAoe+TMz60E9G/wkbZRUk7RS0omSDgI/FxE/TpucQA+fv9lMRkZGpgS+I7VaLUZHRztUkZmZdYoiIusaloyk64CVwMuBJyLi9ySdBnwReA3w8YjYebT9DAwMxIEDB5a2WOsL5XKZ7du3Z13GsrFt2zbK5XLWZZiZLSuSHoqIgem29fqI1w7gHcAAcCNARDweEXnawe+Dkl45XUdJRUkHJB14+umnO1awmZmZ2VLp9eC3FlgNnER75O8lEfEkcBA4b7qOEbE7IgYiYmDdunVLXqiZmZnZUuv14LcbuBbYB9wg6VRJLweQ9FPAW4C/z7A+6zPlcpmIyHTZvHkzSZLMWmeSJGzZsiXzWn2Z18xscfVs8JN0GXAoIm4Drgc2Aq8Hvi7pEeB+4NMR8a0MyzTruOHh4TkFv6GhoQ5VZGZmnfKyrAtYKhGxB9iTfn6B9utbAL6SWVFmXSCXyzE+Pk6hUKDVak16wjdJEpIkYXx8nFwul2GVZma2FHp2xM/MZjY4OEitVqNYLE6auaNYLFKr1RgcHMy6RDMzWwI9/TqXxeLXuZiZmdlyMdvrXHr2Uq+ZLa7p3j+4bdu2DCoxM7OF8qVeMzMzsz7h4GdmZmbWJxz8zMzMzPqEg5+ZmVmfqNfrlEqlSU/zl0ol6vV61qVZhyy74Cfpy5J+KOkLC+h7k6RvS6pJ+rykk5egRDMzs65TrVbJ5/NUKhUajQYRQaPRoFKpkM/nqVarWZdoHbDsgh9wE3DpAvveDZwZEXngH4DfWbSqzMzMulS9XqdQKNBsNie9tB2g1WrRbDYpFAoe+esDXRv8JG1MR+ZWSjpR0kFJZ0bEPUDjKH3vSKdsQ9IVkvYBRMRdEXEobfYgcOqSnoSZmVkXGBkZmRL4jtRqtRgdHe1QRZaVrg1+EbEfuBO4DrgR2BsRj87UXtIOSZvSr0Vgq6TzgGHgo9N0uRzwuLaZWcbK5TKSvCzhsmvXrjkFv507d2Zea68v5XK5M/9izaDbX+C8A9gP/Ai4araGEbF1wuenJG0F7gXeExHPTmwr6RrgELBvpv1JKtIOkKxfv36h9ZuZmZl1ja4d8UutBVYDJwEr59n3DcAzwCkTV0r6IPBu4JKYZb66iNgdEQMRMbBu3bp5HtrMzMys+3R78NsNXEt7ZO6GuXaSdDYwCJwFXC3pjHT9xcBvA5siorn45ZqZ2XyVy2UiwssSLps3byZJkll/hyRJ2LJlS+a19vqS9aXerg1+aj+ccSgibgOuBzZKulDSV4HbgbdJekLSO9P2OyRtknQCcDNweUQ8Sfsev1skCRijPXp4t6SHJX0mi3MzMzPrpOHh4TkFv6GhoQ5VZFnp2nv8ImIPsCf9/AJwTrrpL2dov3XC1zdOWH8n7YdEAF6z+JWamZl1t1wux/j4OIVCgVarNelBjyRJSJKE8fFxcrlchlVaJ3TtiJ+ZmZktnsHBQWq1GsVicdLMHcVikVqtxuDgYNYlWgd07YifmZmZLa5cLsfY2BhjY2NZl2IZ8YifmZmZWZ9w8DMzMzPrE77Ua2Zzcv7552ddgpmZHSMHPzObkwsuuCDrEszM7Bj5Uq+ZmZlZn3DwMzObRr1ep1QqTXrtRalUol6vZ12amdmC9VXwk7RB0gOSDkqqSXp/1jWZWfepVqvk83kqlQqNRoOIoNFoUKlUyOfzVKvVrEs0M1uQvgp+QBO4LCJeD1wM/IGkk7Mtycy6Sb1ep1Ao0Gw2J81uANBqtWg2mxQKBY/8mdmy1LPBT9LGdFRvpaQTJR0EVkTEdwDSeXy/D6zLtFAz6yojIyNTAt+RWq0Wo6OjHarIzGzx9Gzwi4j9tOfovQ64EdgbEY8e3i7pbGAF4L+2mx2jcrmMpJ5Ydu3aNafgt3PnzsxrXYylXC535h8SM+sKvf46lx3AfuBHwFWHV0p6FXAr8MGIeHG6jpKKQBFg/fr1S1+pWZe77777pqzzK17MzJaXXg9+a4HVQAKsBP5V0hrgi8AnI+LBmTpGxG5gN8DAwEB0oFazrnb//fdPWefgZ2a2vPTspd7UbuBaYB9wg6QVwOeBPRFxe6aVmfWQcrlMRPTEsnnzZpIkmfV8kyRhy5Ytmde6GIsv9Zr1l54NfpIuAw5FxG3A9cBG4FeBtwIfkvRwumzIsEwz6zLDw8NzCn5DQ0MdqsjMbPH0bPCLiD0R8d708wsRcU66LomIDROWhzMu1cy6SC6XY3x8nFWrVk0JgEmSsGrVKsbHx8nlchlVaGa2cD0b/MzMFmpwcJBarUaxWJw0c0exWKRWqzE4OJh1iWZmC9LrD3eYmS1ILpdjbGyMsbGxrEsxM1s0HvEzMzMz6xMOfmZmZmZ9wsHPzMzMrE84+JmZmZn1CQc/M1ty9XqdUqk06QnZUqlEve6pss3MOqnvgp+kL0v6oaQvZF2LWT+oVqvk83kqlQqNRoOIoNFoUKlUyOfzVKvVrEs0M+sbfRf8gJuAS7Muwqwf1Ot1CoUCzWaTVqs1aVur1aLZbFIoFDzyZ2bWIT0b/CRtlFSTtFLSiZIOSjozIu4BGlnXZ9YPRkZGpgS+I7VaLUZHRztUkZlZf+vZ4BcR+4E7geuAG4G9EfFotlWZHbtyuYykji/TOVqfXbt2zSn47dy5M5Nzmu9SLpeX4Bc1M+ucXp+5YwewH/gRcNV8OkoqAkWA9evXL35lZmZmZh3WsyN+qbXAauAkYOV8OkbE7ogYiIiBdevWLUlxZmZmZp3U68FvN3AtsA+4IeNazBZFuVwmIjq+TOdofTZv3kySJLOeT5IkbNmyJZNzmu/iS71mttxppv+gL3eSLgN+OSLeK+l44GvA7wDbgZ+nPRL4DPDrEfGV2fY1MDAQBw4cWOqSzXpOvV4nn8/TbDZnbLNq1SpqtRq5XK6DlZmZ9S5JD0XEwHTbenbELyL2RMR7088vRMQ5EfGXEXFeRKyLiJdHxKlHC31mtnC5XI7x8XFWrVo1ZeQvSRJWrVrF+Pi4Q5+ZWYf0bPAzs+4wODhIrVajWCxOmrmjWCxSq9UYHBzMukQzs77Rs5d6F5Mv9ZqZmdly0ZeXes3MzMxsMgc/MzMzsz7h4GdmZmbWJxz8zMzMzPpEr0/ZZmbzUK/XGRkZYe/evTz33HOsXr2aD3zgAwwPD7N3794p7bdt25ZBlWZmtlAe8TMzAKrVKvl8nkqlQqPRICJoNBpUKhXy+Tzf+c53si7RzMyO0ZIFP0nPzaHNb0patVQ1HOXYJ0sqZXFss25Tr9cpFAo0m01ardakba1Wi2azyec+9zmeffbZjCo0M7PFkPWI328C8wp+6fRri+FkwMHPDBgZGZkS+I70wgsv8MADD3SoIjMzWwpLHvwkXSDpPknjkr4taZ/argJOAe6VdG/a9iJJD0j6pqTbJa1O1z8maaukvwb+k6SL0zaPSLonbXOipFsk7Zf0t5J+KV3/IUl3SPqypL+XdPimpOuBnKSHJd201H8OZkcql8tI6opl165dRw1+L774IrVabdK6rOotl8tL+MuYmfWuTj3ccRbweuBJ4G+At0TEf5X0n4H/EBE/kPQK4JPA2yPiXyX9NvCfgR3pPn4UEf9e0jrgm8BbI+K7ktam268B/jIiLpd0MvANSX+RbjsbOBNoAvslfRH4BHBmRGyYrmBJRaAIsH79+sX7kzBbxp5//vmsSzAzs2PQqUu934iIJyLiReBh4PRp2rwZeB3wN5IeBj4IvHrC9s9OaPdXEfFdgIg4fNPRRcAn0r73ASuBw4nt7oh4JiL+Dfgz4N8freCI2B0RAxExsG7dujmepllvW7FiRdYlmJnZMejUiN+PJ3x+YYbjinZA+7UZ9vGvE9pNN8GwgPdFxN9PWimdM017T1BsmSuXy11zybJUKlGpVGa93HvccceRz+cnrfNc32Zmy0vWD3c0gJPSzw8Cb5H0GgBJqyT93DR9HgDOl3RG2u7wpd6vAB+VpHT9WRP6vEPSWkkvB36Z9uXmicc262vDw8MkSTJrm+OPP55zzz23QxWZmdlSyDr47Qaqku6NiKeBDwF/LKlGOwj+/JEd0nZF4M8kPcJPLgF/CkiAmqRH0++H/TVwK+3LzH8aEQci4hnal5Uf9cMd1u9yuRzj4+OsWrVqSgBMkoRVq1bxK7/yK6xdu3aGPZiZ2XKgXr9UI+lDwEBEXLnQfQwMDMSBAwcWryizLlWv1xkdHeXWW299aeaOSy+9lKGhIc/cYWa2TEh6KCIGptvmKdvM7CW5XI6xsTHGxsayLsXMzJZAzwe/iPhD4A8zLsPMzMwsc1nf42dmZmZmHeLgZ2ZmZtYnHPzMzMzM+oSDn5mZmVmfcPAzMzMz6xM9/x6/xSDpaeB/ZV1HD3sF8IOsi7A58++1vPj3Wn78my0v3fh7vToi1k23wcHPMifpwEwvmrTu499refHvtfz4N1teltvv5Uu9ZmZmZn3Cwc/MzMysTzj4WTfYnXUBNi/+vZYX/17Lj3+z5WVZ/V6+x8/MzMysT3jEz8zMzKxPOPhZ5iT9J0kHJb0oadk8GdVvJF0s6e8l/aOkT2Rdj81O0i2Svi/p0axrsaOTdJqkeyX9Xfrfw49lXZPNTNJKSd+Q9Ej6e23Puqa5cvCzbvAo8F7gr7IuxKYn6XhgJzAIvA74NUmvy7YqO4o/BC7Ougibs0PAcET8O+DNwBb/O9bVfgxcGBFvBDYAF0t6c7YlzY2Dn2UuIv4uIv4+6zpsVmcD/xgR/19EPA/8CfBLGddks4iIvwKezboOm5uI+OeI+Gb6uQH8HfCz2VZlM4m259KvSbosi4cmHPzMbC5+Fnh8wvcn8P8pmS0JSacDZwFfz7gUm4Wk4yU9DHwfuDsilsXv9bKsC7D+IOkvgJ+ZZtM1EXFHp+uxedM065bF327NlhNJq4E/BX4zIv4l63psZhHxArBB0snA5yWdGRFdf0+tg591RES8Pesa7Jg8AZw24fupwJMZ1WLWkyQltEPfvoj4s6zrsbmJiB9Kuo/2PbVdH/x8qdfM5mI/8FpJZ0haAfwqcGfGNZn1DEkC/jvwdxHx+1nXY7OTtC4d6UPSy4G3A9/OtKg5cvCzzEl6j6QngHOBL0r6StY12WQRcQi4EvgK7ZvOPxcRB7OtymYj6Y+BB4D/S9ITkn4965psVm8BLgUulPRwurwr66JsRq8C7pVUo/0X47sj4gsZ1zQnnrnDzMzMrE94xM/MzMysTzj4mZmZmfUJBz8zMzOzPuHgZ2ZmZtYnHPzMzMzM+oSDn5nZDCSdIOkv0ldrvF/SeZIOpt9/VtL4UfpXJL1ugce+QNIvLqzyKfv6kKSxxdiXmS1vnrnDzGxmZwFJRGwAkPQZ4NMR8T/S7YXZOkfEbxzDsS8AngO+dgz7MDObxCN+ZtaTJF0mqSbpEUm3puteLemedP09ktan69dJ+lNJ+9PlLZJ+GthLey7OhyVdAfwKsFXSPkmnS3o07X+8pE9L+la674+m6++TNJB+vkjSA5K+Ken2dE5WJD0maXu6/luSfl7S6cBHgKH02OdNOK/j0j4nT1j3j5JeKek/Svq6pL9NRypfOc2fyx9KKkz4/tyEzx9Pz78mafti/RZm1j0c/Mys50h6PXANcGFEvBH4WLppDNgTEXlgH/Bf0/X/BRiNiI3A+4BKRHwf+A3gqxGxISL+H9rT1H08Ii454pBF4AzgrAn7nljPK4BPAm+PiF8ADgD/eUKTH6TrdwFXR8RjwGfSmjZExFcPN4yIF4E7gPek+z4HeCwingL+GnhzRJwF/AnwW/P4M7sIeC1wNrABeJOkt861v5ktD77Ua2a96EJgPCJ+ABARz6brzwXem36+Fbgx/fx24HXt6VIBWCPppHkc7+3AZ9Kp7SYe77A3A68D/iY9xgra06kd9mfp/z40ob7ZfBbYCvwP2vMmfzZdfyrwWUmvSo/x3Xmcw0Xp8rfp99W0g+BfzWMfZtblHPzMrBcJmMt8lIfbHAecGxH/NmknPwmCx3o80Z7L89dm2P7j9H9fYG7/XX4AeI2kdcAvA9el6/8b8PsRcaekC4DyNH0PkV7tUfsEV0yo8ffSkU0z61G+1Gtmvege4Fck/Z8Aktam679Ge4QM4BLal0YB7gKuPNxZ0oZ5Hu8u4COSXnbE8Q57EHiLpNek21dJ+rmj7LMBTDvqGO1J1j8P/D7wdxHxTLrp/wC+l37+4Az7fQx4U/r5l4Ak/fwV4PIJ9x7+bHqfo5n1EAc/M+s5EXEQ+F3gfkmP0A5IAFcBH5ZUAy7lJ/f+XQUMpA81/E/aD1bMRwX4J6CWHu//PqKep4EPAX+cHvtB4OePss//F3jPkQ93TPBZ4AP85DIvtEf4bpf0VeAHM+z3ZuB8Sd8AzgH+Na3xLuA24AFJ3wLGmSF4mtnypfZfHM3MzMys13nEz8zMzKxPOPiZmZmZ9QkHPzMzM7M+4eBnZmZm1icc/MzMzMz6hIOfmZmZWZ9w8DMzMzPrEw5+ZmZmZn3i/wfx/ynxp2CTqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_coefplot(stats_fit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1d)\n",
    "A copy of the training data set is created for you below. You will assign predictions of the training set to this copy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the training set with your fit logistic regression model. Assign the prediction to a new column in the `train_copy` DataFrame. Name that new column `pred_prob`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1d) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['pred_prob'] = stats_fit.predict(train_copy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1e)\n",
    "Classify your predictions on the training set assuming a threshold of 0.5. Assign your classifications to the `pred_class` variable in the `train_copy` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1e) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy['pred_class'] = np.where( train_copy['pred_prob'] > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1f)\n",
    "Calculate the Accuracy of your logistic regression model on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1f) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_copy.loc[ train_copy.y == train_copy['pred_class'] ].shape[0] / train_copy.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will now fit a logistic regression model with the `sklearn` method `LogisticRegression()`. However, before the model can be fit the we have to assemble the data objects in the correct format. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2a) \n",
    "Create the response and input feature array in the format required by `sklearn`. You may use the `dmatrices()` function to create the objects. You should include all pair wise interactions between the inputs, but carefully think through the behavior of the intercept. Assign the response array to `y_sk` and the input feature array to `X_sk`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2a) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sk, X_sk = dmatrices(formula_fit + '-1', data= train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2b)\n",
    "You will now fit the logistic regression model with `sklearn`. You will **not** use the default settings. Rather, you will set the `penalty` argument equal to `'none'`, you will set the `solver` argument equal to `'lbfgs'`, and you will set the `max_iter` argument to 5001. Assign the fitted model to the `sk_none` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2b) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_none = LogisticRegression(penalty='none', solver='lbfgs', max_iter=5001, fit_intercept=True).fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2c)\n",
    "Display the `sklearn` estimated coefficients to the screen, and do not forget to include the intercept.  \n",
    "\n",
    "How do the coefficient estimates compare between the `statsmodels` and `sklearn` model fits? Are they similar or are they very different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2c) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sklearn_coefs(sk_mod):\n",
    "    return list(sk_mod.intercept_.ravel()) + list(sk_mod.coef_.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0588689482203567,\n",
       " 0.1457184088956187,\n",
       " 0.5600327624714894,\n",
       " 2.2416025552227383,\n",
       " -0.10058548536164022,\n",
       " -0.20358860929326453,\n",
       " -0.1655115558867452,\n",
       " -0.7272661076644187,\n",
       " -0.19980661610689598,\n",
       " 0.021289551557704824,\n",
       " -0.6019664978746235,\n",
       " -0.4364409757757376,\n",
       " -0.1257243275930188,\n",
       " -0.06556004071892028,\n",
       " 0.1858599532380458,\n",
       " 0.11671693059023688]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_sklearn_coefs(sk_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sklearn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sklearn\n",
       "Intercept      -0.058878 -0.058869\n",
       "x1              0.145705  0.145718\n",
       "x2              0.560019  0.560033\n",
       "x1:x2           2.241473  2.241603\n",
       "x3             -0.100603 -0.100585\n",
       "x1:x3          -0.203579 -0.203589\n",
       "x2:x3          -0.165509 -0.165512\n",
       "x1:x2:x3       -0.727286 -0.727266\n",
       "x4             -0.199806 -0.199807\n",
       "x1:x4           0.021289  0.021290\n",
       "x2:x4          -0.601959 -0.601966\n",
       "x1:x2:x4       -0.436369 -0.436441\n",
       "x3:x4          -0.125732 -0.125724\n",
       "x1:x3:x4       -0.065539 -0.065560\n",
       "x2:x3:x4        0.185884  0.185860\n",
       "x1:x2:x3:x4     0.116719  0.116717"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sklearn': extract_sklearn_coefs( sk_none)},\n",
    "             index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2d)\n",
    "`sklearn` provides several useful methods for evaluating model performance for us. We do not have to first make predictions and then manually calculate performance metrics, if we are interested in quantities such as Accuracy. The `.score()` method will return the \"scoring function\" which measures performance. The syntax is:  \n",
    "\n",
    "`<your model>.score(<input feature array>, <known response array>)`\n",
    "\n",
    "Accuracy is the default scoring function for logistic regression. Thus, you just need to supply the input feature array as the first argument to the `.score()` method, and the response array as the second argument to the `.score()` method. Behind the scenes, `sklearn` predicts the probability at each input condition, classifies the prediction with the default threshold of 0.5, compares the predicted class to the observed class, and then calculates the fraction of correclty classified observations.\n",
    "\n",
    "Calculate the accuracy of your `sklearn` fit model. How does the accuracy compare to the accuracy calculated from the `statsmodels` fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2d) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sk_none.score(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 03\n",
    "You did not use the default settings when you fit your `sklean` logistic regression model in Problem 02. The default `penalty` argument is `l2` which stands for the L2-norm, and is commonly referred to as the **Ridge penalty**. This problem is focused on studying the behavior of the ridge penalty as you change the inverse of the regularization strength parameter, `C`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3a)\n",
    "Fit a logistic regression model using the default solver settings. However, you must specify those arguments rather than just relying on the default values, that way we know exactly what was run. Specify the `penalty` argument to be `'l2'`, and set the `C` argument to be equal to `1.0`. You must also set the `solver` argument equal to `'lbfgs'` and set the `max_iter` argument equal to 5001. Assign your fit model to the `sk_default` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3a) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_default = LogisticRegression(penalty='l2', solver = 'lbfgs', max_iter = 5001, fit_intercept=True, C=1.0).fit(X_sk, y_sk.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3b)\n",
    "Display the coefficient estimates for the default logistic regression model. How do they compare to the estimated coefficients when the `penalty` term was set to `'none'`? Don't forget about the intercept!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3b) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>sklearn_l2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>-0.082598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.100582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.468322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>1.878686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>-0.091436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "      <td>-0.182673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "      <td>-0.125884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "      <td>-0.520707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>-0.174707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.052878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "      <td>-0.513418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "      <td>-0.293074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "      <td>-0.133728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>-0.050078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.140649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.039561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sklearn  sklearn_l2\n",
       "Intercept      -0.058878 -0.058869   -0.082598\n",
       "x1              0.145705  0.145718    0.100582\n",
       "x2              0.560019  0.560033    0.468322\n",
       "x1:x2           2.241473  2.241603    1.878686\n",
       "x3             -0.100603 -0.100585   -0.091436\n",
       "x1:x3          -0.203579 -0.203589   -0.182673\n",
       "x2:x3          -0.165509 -0.165512   -0.125884\n",
       "x1:x2:x3       -0.727286 -0.727266   -0.520707\n",
       "x4             -0.199806 -0.199807   -0.174707\n",
       "x1:x4           0.021289  0.021290    0.052878\n",
       "x2:x4          -0.601959 -0.601966   -0.513418\n",
       "x1:x2:x4       -0.436369 -0.436441   -0.293074\n",
       "x3:x4          -0.125732 -0.125724   -0.133728\n",
       "x1:x3:x4       -0.065539 -0.065560   -0.050078\n",
       "x2:x3:x4        0.185884  0.185860    0.140649\n",
       "x1:x2:x3:x4     0.116719  0.116717    0.039561"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sklearn': extract_sklearn_coefs( sk_none),\n",
    "               'sklearn_l2': extract_sklearn_coefs(sk_default)},\n",
    "             index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c)\n",
    "Calculate the Accuracy on the training set for the model with the default `penalty` and `C` values. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3c) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf05 = KFold(n_splits=5, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6599999999999999\n"
     ]
    }
   ],
   "source": [
    "ridge_default_c = LogisticRegression(penalty='l2', solver='lbfgs', C=1.0, max_iter=5001, fit_intercept=False)\n",
    "\n",
    "accuracy_ridge_default_c = cross_val_score( ridge_default_c, X_sk, y_sk.ravel(), cv=kf05)\n",
    "\n",
    "print( accuracy_ridge_default_c.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3d)\n",
    "Next, you change the `C` parameter to a very large value of 10000. Fit the logistic regression model again with this large value of `C` and assign the result to the `sk_large_c` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3d) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_large_c = LogisticRegression(penalty='l2', solver = 'lbfgs', max_iter = 5001, fit_intercept=True, C=10000).fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3e)\n",
    "Display the coefficients for the model with large `C` parameter value. How do they compare to the model with `penalty='none'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3e) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>sklearn_large</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>-0.058872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.145712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.560019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>2.241549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>-0.100584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "      <td>-0.203586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "      <td>-0.165506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "      <td>-0.727233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>-0.199803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.021294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "      <td>-0.601954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "      <td>-0.436417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "      <td>-0.125726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>-0.065558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.185853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.116704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sklearn  sklearn_large\n",
       "Intercept      -0.058878 -0.058869      -0.058872\n",
       "x1              0.145705  0.145718       0.145712\n",
       "x2              0.560019  0.560033       0.560019\n",
       "x1:x2           2.241473  2.241603       2.241549\n",
       "x3             -0.100603 -0.100585      -0.100584\n",
       "x1:x3          -0.203579 -0.203589      -0.203586\n",
       "x2:x3          -0.165509 -0.165512      -0.165506\n",
       "x1:x2:x3       -0.727286 -0.727266      -0.727233\n",
       "x4             -0.199806 -0.199807      -0.199803\n",
       "x1:x4           0.021289  0.021290       0.021294\n",
       "x2:x4          -0.601959 -0.601966      -0.601954\n",
       "x1:x2:x4       -0.436369 -0.436441      -0.436417\n",
       "x3:x4          -0.125732 -0.125724      -0.125726\n",
       "x1:x3:x4       -0.065539 -0.065560      -0.065558\n",
       "x2:x3:x4        0.185884  0.185860       0.185853\n",
       "x1:x2:x3:x4     0.116719  0.116717       0.116704"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sklearn': extract_sklearn_coefs( sk_none),\n",
    "               'sklearn_large': extract_sklearn_coefs(sk_large_c)},\n",
    "             index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n"
     ]
    }
   ],
   "source": [
    "ridge_large_c = LogisticRegression(penalty='l2', solver='lbfgs', C=10000, max_iter=5001, fit_intercept=True)\n",
    "\n",
    "accuracy_ridge_large_c = cross_val_score( ridge_large_c, X_sk, y_sk.ravel(), cv=kf05)\n",
    "\n",
    "print( accuracy_ridge_large_c.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3f)\n",
    "Next, reduce `C` to a very small value of 0.0001. Fit the logistic regression model and assign the result to `sk_small_c`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3f) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_small_c = LogisticRegression(penalty='l2', solver = 'lbfgs', max_iter = 5001, fit_intercept=True, C=0.0001).fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3g)\n",
    "Display the coefficients for the model with small `C` parameter value. How do the coefficients compare to the model with `penalty='none'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3g) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sklearn</th>\n",
       "      <th>sklearn_small</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>-0.180583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>-0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.000712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>0.004570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>-0.000307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "      <td>-0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "      <td>-0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "      <td>-0.000245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>-0.000721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.001345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "      <td>-0.000439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "      <td>-0.000981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "      <td>-0.001170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>-0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>-0.000739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sklearn  sklearn_small\n",
       "Intercept      -0.058878 -0.058869      -0.180583\n",
       "x1              0.145705  0.145718      -0.000372\n",
       "x2              0.560019  0.560033       0.000712\n",
       "x1:x2           2.241473  2.241603       0.004570\n",
       "x3             -0.100603 -0.100585      -0.000307\n",
       "x1:x3          -0.203579 -0.203589      -0.000279\n",
       "x2:x3          -0.165509 -0.165512      -0.000004\n",
       "x1:x2:x3       -0.727286 -0.727266      -0.000245\n",
       "x4             -0.199806 -0.199807      -0.000721\n",
       "x1:x4           0.021289  0.021290       0.001345\n",
       "x2:x4          -0.601959 -0.601966      -0.000439\n",
       "x1:x2:x4       -0.436369 -0.436441      -0.000981\n",
       "x3:x4          -0.125732 -0.125724      -0.001170\n",
       "x1:x3:x4       -0.065539 -0.065560      -0.000005\n",
       "x2:x3:x4        0.185884  0.185860       0.000416\n",
       "x1:x2:x3:x4     0.116719  0.116717      -0.000739"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sklearn': extract_sklearn_coefs( sk_none),\n",
    "               'sklearn_small': extract_sklearn_coefs(sk_small_c)},\n",
    "             index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3h) \n",
    "Calculate the Accuracy for the model with small `C` parameter value. How does the Accuracy compare to the other models you have fit?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3h) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.545\n"
     ]
    }
   ],
   "source": [
    "ridge_small_c = LogisticRegression(penalty='l2', solver='lbfgs', C=0.0001, max_iter=5001, fit_intercept=True)\n",
    "\n",
    "accuracy_ridge_small_c = cross_val_score( ridge_small_c, X_sk, y_sk.ravel(), cv=kf05)\n",
    "\n",
    "print( accuracy_ridge_small_c.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3i)\n",
    "Describe the impact of the `C` parameter on the coefficient behavior. What happens to the coefficients when `C` is large compared to when `C` is very small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3i) - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When `C` is large the accuracy increses a little but to **67%** but when `c` is small the accuracy drops ti just **54.5%**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 04\n",
    "The logistic regression function in `sklearn` includes 2 other types of penalties besides the Ridge penalty. You will work with the `penalty='l1'` option in this question, which corresponds to the L1-norm or the **Lasso penalty**. The syntax is similar to the previous question, except that you must change the `solver` argument as well. \n",
    "\n",
    "You must specify the `penalty` argument to be `'l1'` and specify the `solver` argument to be `'saga'` for all parts in this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4a)\n",
    "Fit a logistic regression model with the lasso penalty with the `C` parameter set to 1. Assign the result to the `sk_lasso_default` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4a) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lasso_default = LogisticRegression(penalty='l1', solver='saga', max_iter=5001, fit_intercept=True, C=1.0).\\\n",
    "fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4b)\n",
    "Fit a logistic regression model with the lasso penalty with the `C` parameter set to a large value of 10000. Assign the result to the `sk_lasso_large_c` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4b) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lasso_large_c = LogisticRegression(penalty='l1', solver='saga', max_iter=5001, fit_intercept=True, C=10000).\\\n",
    "fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4c)\n",
    "Fit a logistic regression model with the lasso penalty with the `C` parameter set to a very small value of 0.0001. Assign the result to the `sk_lasso_small_c` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4c) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_lasso_small_c = LogisticRegression(penalty='l1', solver='saga', max_iter=5001, fit_intercept=True, C=0.0001).\\\n",
    "fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4d)\n",
    "Display the coefficient estimates for the 3 different lasso models, `sk_lasso_default`, `sk_lasso_large_c`, and `sk_lasso_small_c` to the screen. What's going on with the coefficient estimates? How are they changing as the value of `C` changes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4d) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>default</th>\n",
       "      <th>large_c</th>\n",
       "      <th>small_c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.095581</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>-0.098584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.036624</td>\n",
       "      <td>0.144804</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.423590</td>\n",
       "      <td>0.558458</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>1.927859</td>\n",
       "      <td>2.235808</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.069726</td>\n",
       "      <td>-0.100406</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.155680</td>\n",
       "      <td>-0.203501</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.062214</td>\n",
       "      <td>-0.164561</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.406430</td>\n",
       "      <td>-0.722587</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.149296</td>\n",
       "      <td>-0.199371</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.017333</td>\n",
       "      <td>0.021879</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.473863</td>\n",
       "      <td>-0.600833</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.151630</td>\n",
       "      <td>-0.432106</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.111226</td>\n",
       "      <td>-0.125994</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.065516</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.096447</td>\n",
       "      <td>0.184865</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.113704</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   default   large_c   small_c\n",
       "Intercept      -0.058878 -0.095581 -0.059364 -0.098584\n",
       "x1              0.145705  0.036624  0.144804  0.000000\n",
       "x2              0.560019  0.423590  0.558458  0.000000\n",
       "x1:x2           2.241473  1.927859  2.235808  0.000000\n",
       "x3             -0.100603 -0.069726 -0.100406  0.000000\n",
       "x1:x3          -0.203579 -0.155680 -0.203501  0.000000\n",
       "x2:x3          -0.165509 -0.062214 -0.164561  0.000000\n",
       "x1:x2:x3       -0.727286 -0.406430 -0.722587  0.000000\n",
       "x4             -0.199806 -0.149296 -0.199371  0.000000\n",
       "x1:x4           0.021289  0.017333  0.021879  0.000000\n",
       "x2:x4          -0.601959 -0.473863 -0.600833  0.000000\n",
       "x1:x2:x4       -0.436369 -0.151630 -0.432106  0.000000\n",
       "x3:x4          -0.125732 -0.111226 -0.125994  0.000000\n",
       "x1:x3:x4       -0.065539  0.000000 -0.065516  0.000000\n",
       "x2:x3:x4        0.185884  0.096447  0.184865  0.000000\n",
       "x1:x2:x3:x4     0.116719  0.000000  0.113704  0.000000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'default': extract_sklearn_coefs( sk_lasso_default),\n",
    "               'large_c': extract_sklearn_coefs(sk_lasso_large_c),\n",
    "             'small_c': extract_sklearn_coefs(sk_lasso_small_c)},\n",
    "             index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4e)\n",
    "Calculate the Accuracy associated the 3 different lasso models and display the results to the screen. Describe the behavior of the model performance as `C` changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4e) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_default_c = LogisticRegression(penalty='l1', solver='saga', C=1.0, max_iter=5001, fit_intercept=True)\n",
    "\n",
    "lasso_large_c = LogisticRegression(penalty='l1', solver='saga', C=10000, max_iter=5001, fit_intercept=True)\n",
    "\n",
    "lasso_small_c = LogisticRegression(penalty='l1', solver='saga', C=0.0001, max_iter=5001, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lasso_default_c = cross_val_score( lasso_default_c, X_sk, y_sk.ravel(), cv=kf05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lasso_large_c = cross_val_score( lasso_large_c, X_sk, y_sk.ravel(), cv=kf05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lasso_small_c = cross_val_score( lasso_small_c, X_sk, y_sk.ravel(), cv=kf05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67\n",
      "0.675\n",
      "0.5349999999999999\n"
     ]
    }
   ],
   "source": [
    "print( test_accuracy_lasso_large_c.mean() )\n",
    "\n",
    "print( test_accuracy_lasso_default_c.mean() )\n",
    "\n",
    "print( test_accuracy_lasso_small_c.mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4f)\n",
    "How are the coefficients different as the `C` parameter changes when you use the Lasso compared to the Ridge penalty?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4f) - SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ridge the as `C` gets smaller the coefficients becomes closer to zero but they are never exactly zero.\n",
    "\n",
    "In Lasso as `c` gets smalls the coefficient becomes zero if the coefficient doesn't metter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 05\n",
    "The previous questions focused on studying the model behavior as the `C` parameter is changed. In this problem you will tune or optimize the `C` parameter using cross-validation. You are allowed to the built-in cross-validation function `LogisticRegressionCV()` to perform the cross-validation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a)\n",
    "\n",
    "Tune the `C` parameter using 10 fold cross-validation for the Ridge Penalty. Assign the result to the `ridge_cv` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5a) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf10 = KFold(n_splits=10, shuffle=True, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_cv = LogisticRegressionCV(penalty='l2', Cs=101, cv=kf10, solver='lbfgs', max_iter=5001, fit_intercept=True).\\\n",
    "fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b)\n",
    "What is the optimal `C` value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5b) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06309573])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_cv.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5c)\n",
    "Display the coefficients associated with the optimal `C` value. How do they compare to the logistic regression model fit with `penalty='none'`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5c) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sk_none</th>\n",
       "      <th>ridge_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>-0.149066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.005149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.214793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>0.862227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>-0.061636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "      <td>-0.081773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "      <td>-0.035314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "      <td>-0.142439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>-0.098530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.102834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "      <td>-0.220562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "      <td>-0.104381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "      <td>-0.127503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>-0.014664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.051121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>-0.069711</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sk_none  ridge_best\n",
       "Intercept      -0.058878 -0.058869   -0.149066\n",
       "x1              0.145705  0.145718    0.005149\n",
       "x2              0.560019  0.560033    0.214793\n",
       "x1:x2           2.241473  2.241603    0.862227\n",
       "x3             -0.100603 -0.100585   -0.061636\n",
       "x1:x3          -0.203579 -0.203589   -0.081773\n",
       "x2:x3          -0.165509 -0.165512   -0.035314\n",
       "x1:x2:x3       -0.727286 -0.727266   -0.142439\n",
       "x4             -0.199806 -0.199807   -0.098530\n",
       "x1:x4           0.021289  0.021290    0.102834\n",
       "x2:x4          -0.601959 -0.601966   -0.220562\n",
       "x1:x2:x4       -0.436369 -0.436441   -0.104381\n",
       "x3:x4          -0.125732 -0.125724   -0.127503\n",
       "x1:x3:x4       -0.065539 -0.065560   -0.014664\n",
       "x2:x3:x4        0.185884  0.185860    0.051121\n",
       "x1:x2:x3:x4     0.116719  0.116717   -0.069711"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sk_none': extract_sklearn_coefs(sk_none),\n",
    "              'ridge_best': extract_sklearn_coefs(ridge_cv)},\n",
    "            index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5d)\n",
    "Tune the `C` parameter using 10 fold cross-validation for the Lasso Penalty. Assign the result to the `lasso_cv` object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5d) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_cv = LogisticRegressionCV(penalty='l1', Cs=101, cv=kf10, solver='saga', max_iter=5001, fit_intercept=True).\\\n",
    "fit(X_sk, y_sk.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5e)\n",
    "What is the optimal `C` value associated with the lasso model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5e) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.06309573])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_cv.C_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5f)\n",
    "Display the coefficients associated with the optimal `C` value for the lasso model. What has your model \"turned into\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5f) - SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>statsmodels</th>\n",
       "      <th>sk_none</th>\n",
       "      <th>lasso_best</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Intercept</th>\n",
       "      <td>-0.058878</td>\n",
       "      <td>-0.058869</td>\n",
       "      <td>-0.184136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1</th>\n",
       "      <td>0.145705</td>\n",
       "      <td>0.145718</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2</th>\n",
       "      <td>0.560019</td>\n",
       "      <td>0.560033</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2</th>\n",
       "      <td>2.241473</td>\n",
       "      <td>2.241603</td>\n",
       "      <td>0.798613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3</th>\n",
       "      <td>-0.100603</td>\n",
       "      <td>-0.100585</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3</th>\n",
       "      <td>-0.203579</td>\n",
       "      <td>-0.203589</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3</th>\n",
       "      <td>-0.165509</td>\n",
       "      <td>-0.165512</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3</th>\n",
       "      <td>-0.727286</td>\n",
       "      <td>-0.727266</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x4</th>\n",
       "      <td>-0.199806</td>\n",
       "      <td>-0.199807</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x4</th>\n",
       "      <td>0.021289</td>\n",
       "      <td>0.021290</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x4</th>\n",
       "      <td>-0.601959</td>\n",
       "      <td>-0.601966</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x4</th>\n",
       "      <td>-0.436369</td>\n",
       "      <td>-0.436441</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x3:x4</th>\n",
       "      <td>-0.125732</td>\n",
       "      <td>-0.125724</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x3:x4</th>\n",
       "      <td>-0.065539</td>\n",
       "      <td>-0.065560</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x2:x3:x4</th>\n",
       "      <td>0.185884</td>\n",
       "      <td>0.185860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x1:x2:x3:x4</th>\n",
       "      <td>0.116719</td>\n",
       "      <td>0.116717</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             statsmodels   sk_none  lasso_best\n",
       "Intercept      -0.058878 -0.058869   -0.184136\n",
       "x1              0.145705  0.145718    0.000000\n",
       "x2              0.560019  0.560033    0.000000\n",
       "x1:x2           2.241473  2.241603    0.798613\n",
       "x3             -0.100603 -0.100585    0.000000\n",
       "x1:x3          -0.203579 -0.203589    0.000000\n",
       "x2:x3          -0.165509 -0.165512    0.000000\n",
       "x1:x2:x3       -0.727286 -0.727266    0.000000\n",
       "x4             -0.199806 -0.199807    0.000000\n",
       "x1:x4           0.021289  0.021290    0.000000\n",
       "x2:x4          -0.601959 -0.601966    0.000000\n",
       "x1:x2:x4       -0.436369 -0.436441    0.000000\n",
       "x3:x4          -0.125732 -0.125724    0.000000\n",
       "x1:x3:x4       -0.065539 -0.065560    0.000000\n",
       "x2:x3:x4        0.185884  0.185860    0.000000\n",
       "x1:x2:x3:x4     0.116719  0.116717    0.000000"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'statsmodels': stats_fit.params,\n",
    "              'sk_none': extract_sklearn_coefs(sk_none),\n",
    "              'lasso_best': extract_sklearn_coefs(lasso_cv)},\n",
    "            index=stats_fit.params.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has turned into just the interaction betweem `x1:x2` and zeroed all other variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
